---
title: "Understanding Ecological Memory Analysis"
output:
  rmarkdown::html_document:
    toc: true
    toc_title: "Contents"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 9,
 fig.height = 4,
  out.width = "100%"
)
```

```{r load-packages, message = FALSE, warning = FALSE}
library(memoria)
library(ggplot2)
library(tidyr)
library(viridis)
library(ranger)
```

This article explains the theoretical foundations of ecological memory analysis and demonstrates advanced usage with the memoria package. For a practical introduction, see the [Quick Start Guide](quick_start.html).

## The Model

Ecological memory analysis fits a model of the form:

$$p_{t} = p_{t-1} + \ldots + p_{t-n} + d_{t} + d_{t-1} + \ldots + d_{t-n}$$

Where:

- $p_{t-1} + \ldots + p_{t-n}$ represents **endogenous memory** (effect of past response on current state)
- $d_{t-1} + \ldots + d_{t-n}$ represents **exogenous memory** (effect of past drivers on current state)
- $d_{t}$ represents the **concurrent effect** (synchronic driver influence)

The `prepareLaggedData()` function transforms input data into this lagged structure:

```{r prepare-lagged-example}
# Using built-in palaeodata
data(palaeodata)

# Define lags (in same units as time column)
lags <- seq(0.2, 1, by = 0.2)

# Create lagged data
lagged_data <- prepareLaggedData(
  input.data = palaeodata,
  response = "pollen.pinus",
  drivers = c("climate.temperatureAverage", "climate.rainfallAverage"),
  time = "age",
  oldest.sample = "last",
  lags = lags,
  scale = FALSE
)

# View structure
str(lagged_data[, 1:8])
```

## Properties of Palaeoecological Data

Three properties of palaeoecological time-series justify using Random Forest for ecological memory analysis.

### Temporal Autocorrelation

Temporal autocorrelation (serial correlation) occurs when successive values of a variable are correlated. This violates the independence assumption of standard regression, producing unreliable coefficient estimates. In palaeoecological data, both drivers and responses typically show strong autocorrelation due to the nature of environmental and ecological processes.

### Multicollinearity

Adding consecutive time lags of the same variables creates high correlations among predictors. This multicollinearity inflates standard errors in traditional regression, making coefficient estimates unstable. The lagged data structure required for ecological memory analysis inherently produces multicollinearity.

### Non-linearity

Biotic responses to environmental drivers are often non-linear. Threshold effects, saturation, and complex interactions between endogenous and exogenous factors create relationships that linear models cannot capture adequately.

**Random Forest handles all three issues**: it makes no distributional assumptions, is insensitive to multicollinearity for variable importance estimation, and naturally captures non-linear relationships and interactions.

## How Random Forest Works

### Regression Trees

Random Forest builds on regression trees, which grow through binary recursive partitioning:
1. Find the split point in each predictor that best separates the response into two groups (minimizing within-group variance)
2. Select the predictor with the best split as the node
3. Repeat recursively on each partition until terminal nodes are reached

```{r tree-example, eval = requireNamespace("rpart", quietly = TRUE) && requireNamespace("rpart.plot", quietly = TRUE), fig.height = 3, fig.cap = "A regression tree predicting pollen abundance from lagged values."}
library(rpart)
library(rpart.plot)

# Fit a simple tree
tree_model <- rpart(
  formula = `pollen.pinus__0` ~ `pollen.pinus__0.2` + `climate.temperatureAverage__0.2`,
  data = lagged_data,
  control = rpart.control(minbucket = 10)
)

rpart.plot(tree_model, type = 0, box.palette = viridis(10, alpha = 0.2))
```

### From Trees to Forest

A Random Forest fits hundreds of trees, each on a random subset of cases and predictors:

1. Sample cases with replacement (bootstrap)
2. At each split, consider only a random subset of predictors (size `mtry`)
3. Grow the tree to maximum depth
4. Repeat for many trees (typically 500+)

Predictions are averaged across trees. This ensemble approach reduces the instability of individual trees while maintaining the ability to capture non-linear relationships.

```{r rf-example}
# Prepare data for ranger
rf_data <- lagged_data[, grepl("pollen.pinus|climate", colnames(lagged_data))]

# Fit Random Forest
rf_model <- ranger(
  data = rf_data,
  dependent.variable.name = "pollen.pinus__0",
  num.trees = 500,
  min.node.size = 5,
  mtry = 2,
  importance = "permutation",
  scale.permutation.importance = TRUE
)

# Model summary
print(rf_model)
```

### Variable Importance

Random Forest computes variable importance through permutation:
1. Fit the model and compute prediction error on out-of-bag data
2. For each variable, randomly shuffle its values and recompute error
3. Importance = increase in error when the variable is permuted

Variables that matter for prediction cause large error increases when shuffled. This measure is robust to multicollinearity because permutation disrupts the variable's contribution regardless of its correlation with other predictors.

```{r importance-example}
# View importance scores
sort(rf_model$variable.importance, decreasing = TRUE)
```

## Significance Testing

Random Forest provides importance scores but no significance test. How do we know if an importance score reflects a real relationship versus chance?

The solution is to add a random benchmark variable. If a predictor's importance equals or falls below the random variable's importance, we cannot distinguish its contribution from noise.

Two benchmark types are available:

- **White noise**: Random values without temporal structure. Fast but may underestimate the null expectation for autocorrelated data.
- **Autocorrelated random walk**: Random values with temporal structure matching the data. More conservative and recommended for palaeoecological analysis.

```{r significance-demo, fig.height = 2, fig.width = 5}
# Compute memory with autocorrelated benchmark
data(palaeodataLagged)

# Simplified call - response and drivers auto-detected from attributes
memory_result <- computeMemory(
  lagged.data = palaeodataLagged,
  random.mode = "autocorrelated",
  repetitions = 100
)

# The yellow band shows the random benchmark distribution
plotMemory(memory_result)
```

Predictors with importance above the yellow band (random median) are considered significant. The width of the band reflects uncertainty across model repetitions.

## Memory Features

The `extractMemoryFeatures()` function quantifies memory patterns:

**Strength**: Maximum importance difference between a component and the random median. Higher values indicate stronger memory effects.

**Length**: Proportion of lags where importance exceeds the random median. Values near 1 indicate persistent memory across all lags.

**Dominance**: Among significant lags, the proportion where one component (endogenous or exogenous) exceeds the other. Values near 1 indicate one component dominates; values near 0.5 indicate balance.

```{r features-example}
features <- extractMemoryFeatures(
  memory.pattern = memory_result,
  exogenous.component = c("climate.temperatureAverage", "climate.rainfallAverage"),
  endogenous.component = "pollen.pinus",
  scale.strength = TRUE
)

knitr::kable(features, digits = 3)
```

## Batch Experiments with virtualPollen

The memoria package includes functions for batch analysis of simulated pollen curves from the [virtualPollen](https://github.com/BlasBenito/virtualPollen) package. These functions (`runExperiment()`, `experimentToTable()`, `plotExperiment()`) enable systematic exploration of how ecological memory varies with species traits and sampling resolution.

**Note**: The virtualPollen package must be installed separately from GitHub to use these functions.

```{r vp-check, eval = FALSE}
# Install virtualPollen if needed
# devtools::install_github("BlasBenito/virtualPollen")

if (requireNamespace("virtualPollen", quietly = TRUE)) {
  library(virtualPollen)

  # Access simulation data
  data(simulation, package = "virtualPollen")
  data(parameters, package = "virtualPollen")

  # Define lags
  lags <- seq(20, 240, by = 20)

  # Run experiment on subset
  experiment <- runExperiment(
    simulations.file = simulation,
    selected.rows = 1:2,
    selected.columns = 1,
    parameters.file = parameters,
    parameters.names = c("maximum.age", "fecundity", "niche.A.mean", "niche.A.sd"),
    sampling.names = "1cm",
    driver.column = "Driver.A",
    response.column = "Pollen",
    time.column = "Time",
    lags = lags,
    repetitions = 30
  )

  # Plot results
  plotExperiment(
    experiment.output = experiment,
    parameters.file = parameters,
    experiment.title = "Example experiment",
    sampling.names = "1cm",
    legend.position = "bottom",
    R2 = TRUE
  )
}
```

## Visualizing Interactions

The `plotInteraction()` function creates 2D response surfaces showing how two predictors jointly affect the response. This works with ranger, randomForest, and rpart models.

```{r interaction-plot, fig.height = 5}
plotInteraction(
  model = rf_model,
  data = rf_data,
  x = "climate.temperatureAverage__0",
  y = "pollen.pinus__0.2",
  z = "pollen.pinus__0",
  point.size.range = c(0.5, 3)
)
```

## Summary

Ecological memory analysis with memoria:

1. **Prepares lagged data** capturing endogenous and exogenous components
2. **Uses Random Forest** to handle autocorrelation, multicollinearity, and non-linearity
3. **Tests significance** using random benchmarks (preferably autocorrelated)
4. **Quantifies patterns** through strength, length, and dominance features

The approach provides a robust, assumption-free method for understanding how past states influence current ecological conditions.
